                  L'analyse de traduction et
               l'automatisation de la traduction
                               





                            RÉSUMÉ
                                
 
      Nous avançons que le concept d'analyse de traductions peut servir de point de départ à
      une nouvelle génération d'aides à la traduction.  Nous montrons que les traductions
      peuvent être analysées et versées dans une mémoire traductionnelle structurée et
      décrivons le concordancier bilingue TransSearch que nous avons mis au point pour
      permettre aux traducteurs d'exploiter cette mémoire traductionnelle. Nous affirmons que
      les analyseurs de traductions peuvent contribuer à la détection des erreurs de traduction
      dans les premiers jets et nous présentons les résultats d'une expérience portant sur la
      détection des faux amis, réalisée dans le cadre du projet TransCheck.  Nous soutenons
      enfin que l'analyse de traductions peut faciliter la transcription directe de traductions
      dictées et présentons le nouveau projet TransTalk.



 1. Introduction
 
 En 1951, Y. Bar-Hillel, qui fut le premier chercheur à se consacrer à temps plein au domaine de la
 traduction automatique (TA), écrivait :
 
     «Dans le cas des domaines cibles où la précision absolue est une condition sine qua non, il faut
      renoncer à la TA pure en faveur de la TA mixte, c'est-à-dire un processus traductionnel faisant
      intervenir l'intelligence humaine.  Ce qui soulève la question suivante : Quelles étapes du
      processus devrait-on confier à un partenaire humain?¯(Bar-Hillel [1], p. 230) 
     
 Quarante-deux ans et trois «générations¯ de systèmes plus tard, la TA pure n'est pas plus généralement
 applicable qu'elle ne l'était à cette époque.  Plus décourageant encore, la TA mixte ne l'est guère plus. 
 Il n'existe pas de données précises aisément accessibles à ce sujet, mais on peut dire à coup sûr que
 la part actuelle de la TA, pure ou mixte, se situe bien en deça de 1 p. cent du marché global de la
 traduction.  Force nous est donc d'en conclure que les chercheurs en TA n'ont pas encore réussi à
 proposer de réponses réalistes et pratiques à la question posée par Bar-Hillel au sujet de la division du
 travail entre l'homme et la machine.
 
 Bar-Hillel lui-même proposa l'idée d'un tandem homme-machine dans lequel le partenaire humain
 interviendrait soit avant, soit après le processus mécanique, «mais de préférence pas quelque part au
 milieu¯.  C'est donc dire que la machine se chargerait de l'essentiel du processus traductionnel. Depuis,
 la «TA assistée par l'hommme¯ est restée le paradigme prédominant dans le milieu de la TA, où l'on a
 continué à demander aux machines d'accomplir une tâche qu'elles n'arrivent pas àbien faire, c'est-à-dire
 traduire.  Et où l'on a continué à demander aux traducteurs d'exécuter des tâches auxquelles ils
 préféreraient se soustraire, comme insérer des codes bizarres dans des textes sources, répondre à des
 questions inattendues sur la parenthésage des syntagmes ou réorganiser d'étranges fouillis de mots en
 langue cible.  Résultat : le marché n'a jamais manifesté beaucoup d'enthousiasme pour ce genre de
 modus vivendi homme-machine. 
 
 Il est devenu évident qu'en général, les machines ne réussissent toujours pas à maîtriser la partie
 essentielle du processus de traduction.  Déjà, en 1980, Martin Kay [18] plaidait en faveur d'un
 renversement des rôles qui aurait pour effet de remettre la machine à «sa place¯, c'est-à-dire celle
 d'assistant du traducteur humain :
 
     «Je veux préconiser une approche au problème selon laquelle on permettrait à la machine de
      prendre en charge graduellement, presque imperceptiblement, certaines fonctions du processus
      général de traduction.  La machine assumerait d'abord des tâches non essentiellement reliées
      à la traduction.  Puis, peu à peu, elle s'attaquerait à la traduction comme telle.  Tout serait une
      question de modestie.  ¸ chaque étape, on ne confierait à la machine que ce qu'elle sait bien
      faire.  Et ainsi, petit à petit, l'oiseau ferait son nid!¯(p. 11) 
     
 C'est précisément pour cette approche réaliste et modeste que le Centre canadien de recherche sur
 l'informatisation du travail (qui porte maintenant le nom de Centre d'innovation en technologies de
 l'information - CITI) a opté, en 1987, lorsqu'il a lancé le projet de poste de travail de traducteur
 (Macklovitch [17]).  Dans sa plus récente incarnation, le poste de travail du CITI met à la disposition du
 traducteur un environnement multi-fenêtres qui lui donne simultanément accès à plusieurs outils, comme
 le traitement de texte en écran partagé, la vérification orthographique, la consultation terminologique et
 lexicographique, la comparaison de fichiers, le compte de mots, l'extraction de textes intégraux, etc.
 (Macklovitch [17]).  Il faut reconnaître que ces fonctions ont plus à voir avec la bureautique qu'avec
 l'automatisation de la traduction elle-même.  Mais suivant le scénario proposé par Kay, nous pouvons
 maintenant tirer profit de cette base informatique en l'enrichissant progressivement d'outils orientés vers
 la traduction.  Dans cette optique, la question centrale peut être formulée comme suit : au-delà de la
 bureautique intégrée, mais en deça de la traduction automatique, que peut-on faire de plus pour
 faciliter la tâche du traducteur?
 
 Nous avançons, dans la suite de cet article, que le concept d'analyse de traductions peut servir de
 fondement à l'élaboration d'une nouvelle génération d'outils informatisés à l'intention du traducteur. La
 deuxième section de cet article est consacrée à une description générale de la notion d'analyse de
 traductions.  Les sections 3, 4 et 5 décrivent les travaux réalisés au CITI sur trois applications : une
 mémoire traductionnelle, un vérificateur de traductions et un système de dictée pour traducteurs.
 
 
 2. L'analyse de traductions
 
 Dans la documentation récente (Dymetman et Macklovitch [14], par exemple), la traduction est souvent
 conceptualisée comme une relation trL1L2(s, t), dont l'extension est un ensemble de paires <S, T>, où S
 est un texte en langue L1 et T un texte en langue L2.  Comme il existe, dans chacune de ces langues,
 un nombre infini de textes, la relation trL1L2 doit être définie de façon récursive, ce qui aura pour
 conséquence que cette relation aura un caractère compositionnel : jusqu'au niveau d'un certain
 ensemble fini d'éléments élémentaires, S et T seront décomposés respectivement en des ensembles
 d'éléments {s1 , s2 , ... , sn} et {t1 , t2 , ..., tn}, de telle façon que pour tout i, la relation 
 trLiL2(Si , Ti) sera également satisfaite.
 
 Un système de TA ordinaire incorpore une spécification quelconque (éventuellement partielle) de la
 relation traductionnelle trL1L2, de même qu'un procédure qui produira, pour n'importe quelle valeur de
 S, une ou plusieurs valeurs T pour lesquelles <S, T> appartiendra à trL1L2.  Un système de TA réversible
 (voir, par exemple, Dymetman [8], Van Noord [21]) peut en outre calculer, pour n'importe quelle valeur
 de T, les valeurs S pour lesquelles <S, T> appartiendra à trL1L2.
 
 Les systèmes de TA tentent de résoudre le problème de la production de traductions, mais, comme l'a
 fait remarquer Debili [7], nous pouvons aussi envisager les traductions du point de vue de la
 reconnaissance.  Nous appellerons donc accepteur de traductions toute procédure qui, à partir d'une
 paire particulière de textes <S, T>, peut déterminer si la relation trL1L2(S, T) est toujours vérifiée. 
 Et nous
 appellerons analyseur de traductions toute procédure récursive at(<S, T>, AAT) qui attribue, aux paires
 <S, T> qui satisfont la relation trL1L2(S, T), un arbre d'analyse traductionnelle AAT.  Un AAT rend explicite
 la structure compositionnelle de la relation traductionnelle.  Par exemple, moyennant une définition
 appropriée de la relation traductionnelle anglais-français, un analyseur de traductions pourrait produire
 un AAT comme celui qui est illustré à la Figure 1.
                               
 
 Figure 1 : Un arbre d'analyse traductionnelle (AAT) 
 
 Isabelle [13] utilise le terme bi-texte pour désigner une structure qui, comme l'AAT, sert à décomposer
 les traductions en leurs correspondances constitutives.  Les AAT sont des descripteurs structuraux des
 analyses de traductions au même titre que les arbres d'analyse ou de parsage sont des descripteurs
 structuraux des analyses grammaticales.
 
 L'analyse de traductions et la TA posent, en principe, des problèmes très semblables : le calcul est basé
 sur la même relation abstraite trL1L2  La différence réside uniquement dans les modes de calcul. Cela
 signifie-t-il que les analyseurs de traductions et les systèmes de TA sont, en pratique, assujettis
 exactement aux mêmes contraintes?  Plus spécifiquement, cela signifie-t-il qu'il n'est possible de réaliser
 des analyseurs de traductions efficaces qu'à la seule condition qu'il soit également possible de réaliser
 des systèmes de TA efficaces?
 
 Il est évident que non.  Dans les rares cas où la TA de haute qualité est possible, il devrait évidemment
 être possible de construire un analyseur de traductions pour les sorties du système de TA.  Dans les cas
 où la TA n'est pas possible, nous soutenons, et c'est ce qui importe, qu'il est malgré tout possible
 d'élaborer des dispositifs capables d'analyser les traductions réalisées par des humains et que ces
 analyseurs auront de nombreuses utilités.  Cette différence découle des exigences pratiques que des
 tâches différentes (la TA par opposition à l'analyse de traductions) imposent au niveau de précision de
 la caractérisation formelle de la relation trL1L2(S, T).
 
 Considérons, par exemple, le modèle qui sous-tend la méthode d'alignement de phrases proposée par
 Brown et al. [3].  Sur le plan conceptuel, ce modèle génère des séquences de paires de textes <S, T>
 qui présentent les caractéristiques suivantes : a) S est une séquence <s1 , s2 , ..., sn> dans laquelle
 chaque si est lui-même une séquence de zéro, une ou deux «phrases¯ et T est une séquence semblable
 <t1 , t2 , ..., tn>; b) une «phrase¯ est une chaîne d'unités lexicales terminée par une unité de ponctuation;
 c) une unité lexicale est une chaîne de caractères encadrée par des caractères délimitateurs; d) la
 longueur l(si) de chaque si (en termes du nombre d'unités contenues) présente une corrélation avec la
 longueur l(ti) de la «phrase¯ correspondante ti, selon une distribution de probabilités pr(l(s) l l(t)) et e)
 cette distribution de probabilités peut être estimée à partir des fréquences observées dans des corpus
 de traductions, comme le corpus bilingue du Journal des débats de la Chambre des communes.
 
 Ce modèle saisit bien l'un des aspects spécifiques de la relation traductionnelle établie entre deux
 langues, à savoir la corrélation de longueur qui existe entre les phrases qui sont des traductions
 réciproques.  En ce sens, il constitue un modèle de traduction, aussi faible soit-il.
 
 Si l'on appliquait un modèle de ce genre à la traduction anglais-français, une phrase anglaise e se
 traduirait plus ou moins par une séquence aléatoire de caractères f, dont la seule propriété notable serait
 d'avoir une longueur l(f) qui est typique de la traduction française d'un phrase anglaise de longueur l(e). 
 Dans la pratique, un tel «système de TA¯ semblerait parfaitement inutile. 
 
 Si, d'autre part, à l'instar de Brown et al., on applique ce modèle à l'analyse de traductions, on obtient
 un système capable de décomposer des traductions existantes en des représentations qui rendent leur
 structure compositionnelle explicite jusqu'au niveau de la phrase.  Le résultat sera un arbre d'analyse
 ayant la forme illustrée à la Figure 2, où les textes S et T sont décomposés en n paires successives de
 blocs de phrases si et ti.
 
 
 
 Figure 2 : L'alignement de phrases en tant qu'arbre d'analyse simple
 
 L'analyse est, à l'évidence, très grossière : aucune correspondance n'est établie au-delà du niveau de
 la phrase.  Pourtant, comme nous le verrons bientôt, ces bi-textes à «faible résolution¯ peuvent servir de
 base à certains outils informatisés très pratiques. 
 
 Évidemment, des analyses plus raffinées offriraient encore plus de possibilités à cet égard.  En fait, il
 n'est pas trop difficile d'imaginer des familles de modèles de traduction un peu plus puissants qui, tout
 en demeurant insuffisants pour les fins de la TA, pourraient néanmoins être utilisés pour expliciter
 davantage de structures dans des traductions existantes (comme les correspondances entre syntagmes
 ou mots).
 
 Pour ce qui est de leur architecture générale, les modèles utilisés pour l'analyse de traductions peuvent
 être très proches de ceux utilisés pour la TA.  La possibilité la plus évidente est peut-être le modèle
 tripartite illustré à la Figure 3.
 
 
 
 Figure 3 : Un modèle tripartite pour l'analyse de traductions
 
 Comme le modèle de transfert bien connu de la TA, ce modèle comprend deux composantes propres
 à chacune des langues (les modèles de langage) et une composante «contrastive¯, propre aux paires
 (le modèle de correspondance).  Les deux composantes unilingues fonctionnent en mode analytique et
 les représentations linguistiques qu'elles produisent sont traitées par le modèle de correspondance, qui
 les relie en une représentation bi-textuelle unique où les correspondances traductionnelles sont rendues
 explicites.  Que ses composantes soient mises en oeuvre au moyen de techniques à base de règles ou
 à base de corpus, ce modèle demeure un modèle naturel.  En fait, la meilleure façon de conceptualiser
 la méthode d'alignement simple basée sur la longueur des phrases, que nous avons déjà mentionnée,
 est de l'envisager comme une instance de ce modèle.
 
 Certaines indications suggèrent que les modèles probabilistes se révéleront extrêmement utiles pour
 l'élaboration d'analyseurs de traductions d'utilité générale.  Tandis que les méthodes à base de règles
 conviennent bien à l'élaboration de modèles «profonds¯ dans des domaines restreints, les méthodes
 probabilistes semblent particulièrement bien adaptées au développement de modèles superficiels
 potentiellement capables de produire des analyses partielles relativement précises de traductions
 générales. 
 
 Quoi qu'il en soit, l'essentiel de notre propos est que l'analyse de traductions, même basée sur des
 modèles de traduction faibles, constitue un point de départ approprié pour le développement d'une
 nouvelle génération d'aides à la traduction.  Nous examinerons maintenant certains de ces outils.
 
 
 3. La mémoire traductionnelle
 
 3.1      Les traductions existantes en tant que ressource
 
 La tendance aux approches à base de corpus en TA découle en partie de la constatation que le fonds
 de traductions existantes constitue une ressource d'une très grande richesse dont le potentiel n'a pas
 encore été pleinement exploité.  En fait, il est évident que les traductions existantes renferment
 infiniment plus de solutions à plus de problèmes de traduction que tout autre outil de référence.
 
 Mais les traducteurs ne pourront exploiter les richesses enfouies dans leurs traductions antérieures que
 lorsqu'ils disposeront des outils leur permettant de les gérer comme des données de traduction plutôt
 que comme des données de traitement de texte.  Et c'est précisément à cela que sert un analyseur de
 traductions : transformer des données de traitement de texte en des structures bi-textuelles qui rendent
 explicites les correspondances traductionnelles.
 
 Une fois les traductions existantes structurées en bi-textes, les segments correspondants en langue
 source et en langue cible sont systématiquement interreliés.  Plus particulièrement, tout segment qui
 renferme une occurrence d'un problème de traduction est relié à un segment qui renferme une solution
 toute faite à ce problème.  S'ils disposent des moyens nécessaires pour créer, stocker et interroger de
 telles structures bi-textuelles, les traducteurs pourront transformer leur production antérieure en une
 mémoire traductionnelle exploitable et extrêmement efficace. 
 
 3.2      TransBase
 
 Pour rendre accessibles les résultats des analyses traductionnelles de grandes quantités de texte, nous
 avons conçu un modèle simple de mémoire traductionnelle structurée, que nous avons appelé
 TransBase.  Ce modèle possède les mêmes caractéristiques de base que les systèmes d'extraction de
 textes intégraux : il peut gérer des quantités arbitraires de texte, il peut être augmenté de façon
 incrémentielle et il assure un accès rapide au contenu textuel de la base de données.  Ce qui le distingue
 essentiellement de ces systèmes, c'est sa capacité à stocker des représentations bi-textuelles.
 
 Une base de données TransBase se construit à l'aide d'un analyseur de traductions semblable à celui
 qui est illustré à la Figure 2.  Chacun des textes d'une paire de traductions réciproques fait l'objet d'une
 analyse linguistique qui le décompose en ses éléments structuraux (paragraphes, phrases, etc.) et
 détermine son contenu lexical.  Cette information est stockée dans deux composantes distinctes de la
 base de données, propres à chacune des langues en présence, et indexée de façon à permettre l'accès
 rapide à n'importe quelle partie du texte.  Un «analyseur de correspondances¯, basé sur les techniques
 décrites dans Simard, Foster et Isabelle [20], utilise ensuite ces analyses linguistiques pour construire
 une «carte traductionnelle¯ au niveau de la phrase, qui est également stockée dans la base de données. 
 Cette structure et le mode de construction de la base de données sont illustrés à la Figure 4.
 
 
 Figure 4 : Structure générale de la base de données TransBase
 
 Dans la base de données, les textes source et cible sont traités de façon symétrique.  Cependant,
 comme la directionalité de la traduction peut être importante pour l'utilisateur, TransBase peut enregistrer
 laquelle des deux langues est la langue source. 
 
 3.3      TransSearch
 
 Il existe de nombreuses façons d'exploiter cette mémoire traductionnelle.  La première qui vient à l'esprit,
 et celle qui est probablement la plus universellement utile, consiste à fournir aux traducteurs des outils
 qui leur permettront d'interroger le contenu textuel de la base de données TransBase. Certains auteurs
 (voir, par exemple, Church et Gale [6]) ont déjà suggéré qu'un outil capable de produire des
 concordances bilingues serait utile aux lexicographes bilingues.  Il est plutôt évident qu'un concordancier
 bilingue serait également utile aux traducteurs.  Il se peut, par exemple, qu'en rencontrant, dans un texte
 de départ anglais, un idiotisme tel que to be out to lunch ou to add insult to injury, le traducteur ne soit
 pas certain de l'équivalent français approprié.  Il se peut aussi qu'il ne trouve pas de réponse satisfaisante
 dans les dictionnaires bilingues traditionnels.  S'il disposait d'un concordancier bilingue, il pourrait alors
 interroger une base de données bi-textuelles du genre de TransBase et en extraire des exemples de ces
 expressions, accompagnées de leurs traductions.  Cela serait pratique non seulement pour les
 idiotismes, mais aussi pour la terminologie spécialisée ou pour les tournures et formules propres à
 certains domaines (To whom it may concern..., Attendu que...).  On trouvera, dans Macklovitch [16], un
 exposé plus détaillé de cette question.
 
 Le logiciel TransSearch est justement cet outil : il permet d'extraire de la base de données des
 occurrences d'«expressions¯ précises et de les afficher à l'intérieur de leur contexte bilingue.  Étant
 destiné principalement aux traducteurs, qui sont susceptibles de l'utiliser simplement comme source de
 référence supplémentaire, ce logiciel est conçu pour être exploité en mode interactif et pour donner des
 réponses en temps réel, ce qui est assuré par l'inclusion d'index de mots dans le modèle TransBase. 
 
 Comme la plupart des traducteurs ne sont pas des experts en informatique, nous avons accordé
 beaucoup d'attention à la convivialité de l'interface de TransSearch.  En utilisant un langage
 d'interrogation intuitif et à orientation graphique, il est facile pour l'utilisateur d'effectuer des 
 recherches
 complexes dans la base de données.  Chacune de ces interrogations définit une expression logique
 portant sur des séquences de mots : lorsque l'interrogation est lancée, le système extrait de la
 composante alignement de la base de données tous les couples qui correspondent à cette expression. 
 L'inclusion de dictionnaires et de descriptions morphologiques du français et de l'anglais permet en outre
 à TransSearch de repérer automatiquement les formes fléchies des éléments recherchés.
 
 Les résultats d'une interrogation sont normalement présentés en deux colonnes, les traductions
 réciproques étant affichées côte-à-côte.  L'utilisateur peut alors examiner chacune des solutions
 proposées à l'intérieur du document dont elle a été extraite, ou rassembler toutes les solutions repérées
 accompagnées d'une petite portion de leur contexte immédiat, selon le mode de présentation habituel
 des concordances.
 
 La Figure 5 présente un exemple type des résultats obtenus avec TransSearch.  Dans cet exemple,
 l'utilisateur a interrogé le système pour trouver des occurrences de l'expression anglaise to take X to
 court qui ne sont pas traduites en français par poursuivre X ou intenter un (ou des) procès à X et la base
 de données interrogée était constituée des traductions du Journal des débats de la Chambre des
 communes de 1986.  Tous les traducteurs à qui nous avons montré le fonctionnement de ce système
 en ont conclu qu'un concordancier bilingue leur serait très utile.
 
 
 
   Figure 5 : Exemple des résultats obtenus avec TransSearch
                                
 
 4. La vérification de traductions
 
 4.1      L'analyse de traductions et la détection d'erreurs
 
 Depuis quelques années, on voit apparaître sur le marché du logiciel des outils critiques conçus pour
 aider les rédacteurs à améliorer leurs textes, grâce à la détection des problèmes potentiels
 d'orthographe, de grammaire et même de style.  Si ces outils peuvent, en principe, aider les traducteurs
 à corriger les erreurs de rédaction contenues dans leurs traductions, ils ne peuvent aucunement les aider
 à corriger les erreurs de traduction au sens strict du terme, c'est-à-dire les correspondances erronées
 entre le texte source et le texte cible.  Par exemple, ils ne peuvent pas les aider à repérer les contresens
 ou les faux sens, c'est-à-dire les cas où les deux textes sont individuellement corrects et signifiants, mais
 ne sont pas, en l'occurrence, des traductions réciproques.  De telles erreurs ne peuvent être détectées
 que par un dispositif qui examine simultanément le texte source et le texte cible : en d'autres termes, un
 dispositif qui incorpore un analyseur de traductions.
 
 Moyennant un analyseur de traductions capable de reconstruire un sous-ensemble quelconque Cset des
 correspondances observables dans les résultats d'une opération de traduction, et moyennant un
 ensemble quelconque de contraintes C auxquelles doivent satisfaire les correspondances admissibles,
 un vérificateur de traductions est un dispositif qui aide le traducteur à s'assurer que le sous-ensemble
 Cset respecte effectivement les contraintes C.  Cette capacité exige la présence d'un analyseur de
 traductions basé sur un modèle de traduction «robuste¯, un modèle qui est capable de détecter les
 correspondances réelles susceptibles de dévier de la norme définie par C.
 
 Le problème général de la qualité des traductions est une question manifestement complexe et
 frustrante.  Nous n'avons certainement pas l'intention de proposer une mesure ou une méthode globale
 pour évaluer les traductions.  Notre but est plus modeste : nous désirons seulement cerner certaines
 caractéristiques particulièrement simples qui sont recherchées par la plupart des traducteurs et mettre
 au point quelques outils qui les aideront à vérifier si leurs traductions possèdent ces caractéristiques. 
 
 Une première caractéristique souhaitable et plutôt évidente est l'exhaustivité.  En effet, toutes les parties
 d'un texte source devraient normalement avoir un équivalent dans le texte cible.  Mais il arrive parfois aux
 traducteurs de faire des erreurs d'omission, en oubliant par exemple de traduire une phrase, un
 paragraphe, voire un page entière.  Dans de tels cas, un analyseur de traductions efficace devrait être
 en mesure d'établir qu'un segment du texte source est mis en correspondance avec un segment vide
 dans le texte cible.  Le dispositif de vérification pourrait alors en informer le traducteur, en lui signalant
 l'existence d'un problème éventuel dans son premier jet. 
 
 Une deuxième caractéristique candidate est la cohérence ou l'uniformité terminologique.  En traduction
 technique, il est de rigueur d'utiliser systématiquement le même terme pour traduire toutes les
 occurrences d'un terme particulier du texte source.  Un processus d'analyse permettant de faire ressortir
 toutes les correspondances terminologiques entre une traduction et sa source devrait vraisemblablement
 aider les traducteurs à respecter le principe de l'uniformité terminologique.
 
 Autre caractéristique : les traductions sont censées être exemptes d'interférences linguistiques provenant
 de la langue source.  Dans certains cas, ces interférences mènent à des constructions boiteuses en
 langue cible, que l'on peut souvent détecter sans même se référer au texte source.  Par exemple, si le
 mot anglais address est traduit en français par addresse (avec deux d), un vérificateur orthographique
 ordinaire devrait être mesure de détecter cette erreur.  Mais il y a aussi des cas où l'interférence mène
 non pas à des mots mal orthographiés, mais bien à des erreurs de traduction. Les faux amis, par
 exemple, ont tendance à provoquer ce genre d'interférence.
 
 Le mot me de la langue Le et le mot mf de la langue Lf sont des mots apparentés lorsque leur forme est
 semblable en raison d'une étymologie commune.  C'est le cas, par exemple, du mot anglais government
 et du mot français gouvernement.  Le plus souvent, ces mots sont non seulement des homonymes trans-linguistiques, mais aussi des synonymes.  Dans certains cas, cependant, il n'y a pas de synonymie.  Par
 exemple, les mots apparentés anglais/français suivants ont des sens complètement différents :
 <actual/actuel>, <library/librairie>, <physician/physicien>.  Ces mots apparentés sont dits des «faux amis¯
 parce que leur ressemblance morphologique crée une attente sémantique qui peut induire en erreur. 
 La phrase Max se rendit à la librairie est parfaitement correcte en français, mais comme traduction de
 Max went to the library, elle constitue un cas flagrant d'erreur de traduction.  Si un analyseur de
 traductions était capable de reconnaître, dans une traduction, une correspondance établie entre des
 mots apparentés reconnus comme des faux amis, il pourrait marquer cette correspondance comme une
 erreur possible que le traducteur pourrait ensuite vérifier.
 
 Il existe probablement plusieurs autres types d'erreurs de traduction qu'un analyseur de traductions
 pourrait aider à déceler.  La recherche dans ce domaine ne fait que commencer.  Afin d'avoir un meilleur
 aperçu du potentiel pratique de cette approche, nous avons réalisé une expérience portant sur la
 détection des faux amis dans des traductions réelles.
 
 
 
 
 
 4.2      Une expérience portant sur la détection des faux amis
 
 Les faux amis (FA) peuvent être subdivisés en faux amis absolus ou partiels.  Les FA absolus, comme
 ceux qui sont cités dans les exemples précédents, se caractérisent par le fait que leurs significations sont
 complètement disjointes; ils ne peuvent donc jamais être utilisés comme des traductions réciproques. 
 Les FA partiels, par contre, ont des sens qui se recoupent partiellement et ils peuvent être des
 équivalents traductionnels dans un sous-ensemble particulier de leurs emplois possibles.  Par exemple,
 le verbe français examiner est parfois l'équivalent ( ) et parfois le non-équivalent ( ) du verbe anglais
 to examine :
 
     The doctor examined his patient   _Le médecin examina son patient
     The professor examined his students   Le professeur examina ses étudiants
 
 En nous concentrant dans un premier temps sur le problème plus facile des FA absolus, nous avons
 réalisé une expérience visant à évaluer 1) l'ampleur du problème dans des traductions réelles et 2)
 l'efficacité de certaines méthodes de détection simples.
 
 Nous avons élaboré un analyseur de traductions AT1 qui instancie le modèle de la Figure 1 de la façon
 suivante : les modèles de langage pour le français et l'anglais sont réduits à des processus de
 segmentation en mots (tokenisation) et d'analyse morphologique (basés sur un dictionnaire et sur un
 ensemble de règles de flexion).  Ces modèles de langage produisent une représentation morphologique
 simple du texte d'entrée : chaque unité lexicale est représentée comme l'ensemble des formes des
 entrées lexicales dont elle est une instance possible.  Le modèle de correspondance utilisé dans AT1
 est simplement le programme d'alignement de phrases mis au point par Simard, Foster et Isabelle [20]. 
 La représentation qu'il produit est une séquence <<e1 , f1>, <e2 , f2>, ...<en , fn>>, dans laquelle chaque
 ei est une séquence de zéro, une ou deux phrases du texte anglais représentées morphologiquement,
 chaque fi est une séquence de zéro, une ou deux phrases du texte français représentées
 morphologiquement, et chaque <ei , fi> est une correspondance traductionnelle.
 
 Nous avons extrait de van Roey et al. [22] une liste de 145 paires de mots classifiés comme des faux
 amis absolus : <accommodate/accommoder>, <actually, actuellement>, etc..  Nous avons ensuite
 réalisé un vérificateur simple qui aurait pour fonction d'examiner les résultats produits par AT1 et
 d'identifier, pour chaque paire de mots <Me , Mf>, l'ensemble de paires de phrases <ei , fi> satisfaisant
 la condition Me   ei (c'est-à-dire que ei contient le mot me) et Mf   ef.  Cette condition peut évidemment
 être satisfaite par des paires de phrases où me et mf sont présents sans toutefois être utilisés comme
 des traductions réciproques.
 
 Nous avons ensuite testé ce dispositif relativement simpliste sur un corpus composé des traductions du
 Journal des débats de la Chambre des communes couvrant une période d'un an.  Après vérification
 manuelle des résultats, nous avons constaté qu'un grand nombre d'erreurs de traduction réelles avaient
 été détectées, comme dans l'exemple suivant :
 
   The peace movement in Canada is composed of physicians, members of the church, [...]
   ->  Le mouvement canadien pour la paix compte dans ses rangs des physiciens, des
    ecclésiastiques, [...]
                        (Journal des débats, 1987/09/29)
                                                               
     There are parts of this bill which concern librarians and the artistic community.
     ->  Quelque part dans ce projet de loi, il est question des libraires et des artistes.
                             (Journal des débats, 1987/11/30)
                                                               
 Mais, comme on peut le voir dans le Tableau 1, les résultats présentaient aussi un niveau de «bruit¯
 très élevé.
 
                               
                                                      
                               
 Tableau 1 : Résultats de l'extraction de FA dans les sorties de AT1
                                
 Ce bruit provenait de trois sources différentes.  Premièrement, il y avait des cas où la «fausseté¯
 (par allusion à faux amis) de <Me , Mf>  était attribuable à la catégorie grammaticale (POS) des
 deux mots en présence.  Par exemple, le nom français local et le nom anglais local sont des faux
 amis absolus, mais leurs homographes adjectivaux n'en sont pas.  Le vérificateur ne tenant pas
 compte de l'information grammaticale, il a relevé des cas non pertinents.  Deuxièmement, une
 certaine proportion de bruit était générée par des citations non traduites.  Par exemple, le mot
 anglais agenda et le mot français agenda sont des FA absolus.  Comme ils sont parfaitement
 identiques, notre vérificateur a été incapable de les distinguer et a donc extrait des cas où le mot
 agenda apparaissait des deux côtés, pour la simple raison que l'un des textes le renfermait sous
 la forme d'une citation non traduite de l'autre langue.  Troisièmement, il y avait des cas où Me et
 Mf apparaissaient effectivement dans des phrases qui étaient des traductions réciproques, mais
 où ces mots n'étaient pas eux-mêmes utilisés comme des équivalents traductionnels.  Notre
 modèle de correspondance (c'est-à-dire d'alignement de phrases) était simplement trop grossier
 pour éliminer ces cas.  Ces sources de bruit sont ventilées dans le Tableau 2.
 


 
 Tableau 2 : Catégories de bruit relevées dans les FA extraits des sorties de AT1
                                
 Ces résultats indiquaient clairement qu'il fallait incorporer la catégorisation grammaticale.  Nous
 avons donc remplacé l'analyseur de traductions AT1 par un nouvel analyseur, AT2, qui se
 distinguait du premier en ce que ses deux modèles de langage incorporaient le programme de
 catégorisation grammaticale de Foster [10].  On a ensuite modifié le processus de recherche pour
 tenir compte de l'information grammaticale associée à nos 145 paires de FA.  Cette méthode a
 donné de bien meilleurs résultats, comme on peut le constater dans les Tableaux 3 et 4.
 


 
 Tableau 3 : Résultats de l'extraction de FA dans les sorties de AT2
                               
                                

 
 Tableau 4 : Catégories de bruit relevées dans les FA extraits des sorties de AT2
                                
 La catégorisation grammaticale a réduit considérablement le niveau de bruit, tout en n'exerçant
 qu'un effet marginal sur le nombre de cas rappelés (perte d'un cas).  Cette amélioration
 spectaculaire est en grande partie attribuable à la résolution des problèmes liés à un petit nombre
 de mots utilisés fréquemment (comme le cas du mot local, mentionné précédemment).  Une partie
 du bruit restant est due à des erreurs de catégorisation grammaticale, mais la majeure partie
 découle maintenant de la grossièreté de notre modèle de correspondance.
 
 Il ne fait aucun doute que de meilleurs modèles permettraient d'améliorer la détection des faux
 amis.  Cependant, la performance de la méthode de faible coût algorithmique que nous avons
 testée ici pourrait fort bien s'avérer suffisante pour les applications réelles.
 
 
 5. La dictée de traductions : TransTalk
 
 Nous sommes revenus quelques fois, dans cet article, sur le fait que des modèles de traduction faibles,
 s'ils sont employés de façon réaliste, peuvent offrir au traducteur des outils efficaces qui ne lui imposent
 pas de contraintes artificielles.  Considérant que de nombreux traducteurs préfèrent dicter leurs textes
 plutôt que de les dactylographier eux-mêmes, un module de dictée automatique constituerait une
 addition fort utile au poste de travail de traducteur (Gurstein et Monette [11]).
 
 La technologie de la reconnaissance automatique de la parole est actuellement limitée aux vocabulaires
 restreints et elle est, de ce fait, inapplicable à la tâche de la plupart des traducteurs. Une possibilité
 intéressante, cependant, serait le couplage d'un module de reconnaissance de la parole et d'un modèle
 de traduction (faible).  Le modèle de TA servirait alors à faire des prédictions probabilistes quant aux
 énonciations susceptibles d'être produites librement par le traducteur, afin de réduire dynamiquement
 le «vocabulaire réel probable¯ envisagé par le module de reconnaissance de la parole pour chaque unité
 de dictée (phrase ou paragraphe) et ce, jusqu'au point où la reconnaissance complète de ces unités
 pourrait être tentée.
 
 Il est évident, par exemple, que la composition probabiliste du vocabulaire considéré par un module de
 reconnaissance de la parole qui tente de décoder la phrase Ces impôts cachés doivent être acquittés
 par les pauvres aussi bien que par les riches sera très différente selon que sa source anglaise The poor
 as well as the rich have to pay these hidden taxes est ou non connue du module.  Il est beaucoup plus
 probable, par exemple, que la traduction française de cette phrase anglaise renferme le mot impôts
 qu'une phrase française choisie au hasard.  Il semble donc raisonnable d'espérer qu'un modèle de
 traduction faible puisse rendre cette composition accessible au module de reconnaissance de la parole.
 
 Cette idée a été avancée par Dymetman, Foster et Isabelle [9] ainsi que par Brown et al. [4].  Nous avons
 entrepris un projet de collaboration avec le groupe de reconnaissance de la parole du Centre de
 recherches informatiques de Montréal (CRIM), le projet TransTalk, qui vise à démontrer la faisabilité de
 cette approche, en utilisant l'anglais comme langue source et le français comme langue de dictée.  Nous
 avons l'intention de nous limiter, au début, à la dictée de mots isolés, puis de passer progressivement
 à la parole continue.  Les projets TransSearch et TransCheck décrits précédemment comportaient
 l'élaboration d'analyseurs de traductions incorporant des modèles de langage pour le français et l'anglais
 et un modèle de correspondance français-anglais (alignement de phrases) qui ont été entraînés sur le
 corpus du Journal des débats de la Chambre des communes.  Ce corpus, ou domaine, est donc un
 choix tout naturel pour le projet TransTalk, puisque les modules existants constitueront alors des
 ressources fondamentales pour TransTalk.  On peut en fait envisager TransTalk comme un système
 incorporant un analyseur de traductions fort semblable à ceux que nous avons déjà décrits, sauf qu'il a
 la capacité de traiter une langue cible parlée, plutôt qu'écrite.
 
 TransTalk est basé sur un modèle probabiliste p de dictée de traduction qui met en relation une unité
 textuelle anglaise écrite e, sa traduction française écrite f (pour simplifier, nous supposerons que ces
 unités textuelles sont des phrases) et s, la réalisation acoustique de f.  Les unités e et s sont toutes deux
 connues du système, qui a pour tâche de produire une estimation $f  de l'unité f effectivement
 formulée par le traducteur.
 
 
 
 L'on est donc amené à définir $f comme :
 
                   $f = argmaxf  p(f l e, s)
                                
 c'est-à-dire que $f  est la phrase française la plus probable selon le modèle p, étant donné la phrase
 source anglaise et la réalisation acoustique de la phrase française.
 
 En utilisant la formule de Bayes, on peut réécrire cette équation comme suit :
 
             $f = argmaxf  p(s  l e, f) p(f l e) 
                 = argmaxf  p(s l f) p(f l e) 
                                
 la dernière égalité étant une conséquence de l'assomption modérée suivante : une fois que f est connue,
 les connaissances supplémentaires sur e n'ajoutent rien à la détermination de s.
 
 Cette équation rappelle fortement la «formule fondamentale¯ de la reconnaissance statistique de la
 parole (Bahl et al. [2]) :
 
                  $f = argmaxf  p(s l f) p(f)
                                
 où les distributions p(s l f) et p(f) sont appelées respectivement le modèle acoustique et le modèle de
 langage.  Dans la situation envisagée ici, le modèle de langage pur p(f) a été remplacé par un «modèle
 de langage conditionnel¯ p(f l e), dans lequel la connaissance de e «affine¯ la structure statistique du
 modèle de langage, en le forçant en particulier à «concentrer¯ son attention sur un sous-ensemble lexical
 restreint de la langue.  On peut mesurer quantitativement cet «affinement¯ au moyen de la perplexité,
 une quantité relative à la théorie de l'information qui mesure l'incertitude moyenne qu'un modèle de
 langage manifeste à l'égard du prochain mot devant apparaître dans un texte naturel, après avoir vu les
 mots précédents : moins un modèle est perplexe, plus il est prédictif (Jelinek [15]).  Brown et al. [4]
 décrivent les résultats d'une expérience qu'ils ont réalisée sur le Journal des débats en utilisant un de
 leurs modèles de traduction les plus simples (du français àl'anglais, dans leur cas).  Ces résultats
 révèlent que la perplexité par mot de leur modèle de langage pur (anglais) s'établit en moyenne à 63,3,
 tandis que la perplexité de leur modèle de langage conditionnel chute à une moyenne de 17,2.  Ces
 résultats sont très encourageants pour la dictée, car ils signifient que le module acoustique devrait
 pouvoir faire un choix, étant donné un mot anglais parlé, parmi en moyenne 17,2 candidats
 équiprobables proposés par le modèle de langage conditionnel, par opposition à 63,3 candidats
 équiprobables proposés par le modèle de langage pur.
 
 Plusieurs approches sont possibles pour la modélisation de p(f l e).  Une première approche, proposée
 par l'équipe IBM, consiste à utiliser la formule de Bayes pour écrire, par analogie à la formulation
 standard du problème de reconnaissance de la parole :
 
                    p(f l e)  _p(e lf) p(f)
                                
 où (selon leur terminologie) p(e l f) correspond au «modèle de traduction¯, qui joue un rôle semblable
 à celui du modèle acoustique dans la reconnaissance de la parole.  Cela nous amène par conséquent
 à une formule symétrique pour l'ensemble du modèle de dictée de traduction, dans laquelle p(f) est le
 modèle de langage, p(s l f) est le modèle acoustique et p(e l f) est le modèle de traduction.  Cette
 méthode présente deux avantages : (1) elle repose sur un seul modèle de langage pour le français et
 (2) les travaux réalisés chez IBM sur la TA statistique semblent indiquer que des approximations même
 grossières de p(e l f), lorsqu'elles sont couplées à un bon modèle de langage pour le français, donnent
 des approximations acceptables pour le modèle de langage conditionnel p(f l e).  C'est comme s'il y avait
 une «division du travail¯ entre p(f), qui est responsable de la structure correcte des phrases françaises,
 et p(e lf), qui est chargé d'apparier les phrases anglaises et françaises (d'où le terme quelque peu
 trompeur de «modèle de traduction¯), sans trop 
 tenir compte de la structure interne du français ou de celle de l'anglais (voir [9] pour plus de détails).
 Cette méthode présente toutefois une lacune importante au niveau du traitement : elle exige la réalisation
 d'une recherche étendue parmi les phrases f pour maximiser p(e l f) p(f) (sans compter le facteur p(s l
 f), ce qui ne fait qu'aggraver les choses).  On sait que cela pose de sérieuses difficultés pratiques en
 termes de résultats de recherche non optimaux ainsi qu'en termes de temps de traitement, ce dernier
 facteur étant évidemment de toute première importance pour une application de dictée.
 
 Une deuxième approche à la modélisation de p(f l e) consiste à considérer a priori une certaine famille
 paramétrisée de modèles de langage p (f) pour le français, à décrire une mise en correspondance
 e  (e), puis à définir le modèle de langage conditionnel au moyen de :
 
                      p(f l e) = p (e)(f)
                                
 Bien qu'elle présente l'inconvénient d'utiliser plus qu'un modèle de langage de référence pour le français,
 cette approche peut être mise en oeuvre efficacement si la famille p (f) est bien choisie. Nous examinons
 actuellement la possibilité d'adapter un modèle de langage proposé dans [10].  Ce modèle est une sorte
 de modèle markovien caché «tri-POS¯, qui dépend de deux familles de paramètres.  La première famille
 ai, j, k, donne la probabilité de générer un mot de catégorie grammaticale POSk, les mots de catégories
 grammaticales POSi et POSj ayant déjà été générés.  La deuxième famille, bi, m, donne la probabilité
 qu'une catégorie grammaticale donnée POSj soit associée au mot m.  Cela signifie, sur le plan
 conceptuel du moins, que le modèle génère d'abord des chaînes de catégories grammaticales, en
 utilisant la fenêtre du contexte des deux catégories grammaticales déjà générées, puis «décore¯ chaque
 catégorie grammaticale avec un mot donné, dépendant uniquement de cette catégorie grammaticale. 
 Les paramètres ai, j, k représentent une approximation de la structure «grammaticale¯ du français, tandis
 que les paramètres bi, m représentent une approximation de sa structure «lexicale¯.
 
 Nous nous proposons de faire l'essai d'un schème où ces paramètres varieront dynamiquement selon
 la phrase source observée e.  Une possibilité intéressante serait de maintenir les «paramètres
 grammaticaux¯ à leurs valeurs globales fixes en langue française (sans tenir compte de l'influence de
 la composition grammaticale de la phrase anglaise sur sa traduction), tout en modifiant les paramètres
 «lexicaux¯ selon la composition lexicale de la phrase anglaise.  La première famille de paramètres peut
 être estimée de façon fiable sur un corpus français suffisamment étendu, tandis que la deuxième famille
 de paramètres, qui dépend de e, peut être estimée si l'on fait certaines hypothèses simplificatrices
 s'apparentant au modèle de traduction 1 de Brown et al. [5]. Essentiellement, chaque bi, m f (e) est
 considéré être la moyenne des contributions p (mf l me , POSi) faites par chaque mot anglais me de e
 à la probabilité de réaliser la catégorie grammaticale POSi dans le mot français mf.  Pour estimer les
 paramètres p (mf l me , POSi), il faut partir d'un corpus d'apprentissage pré-aligné composé de bi-textes
 anglais-français (voir section 3). Il est alors possible de faire des estimations initiales pour les paramètres
 p (mf l me , POSi), puis d'utiliser des techniques de réestimation standard (voir [5]) sur ce corpus
 d'apprentissage pour maximiser l'efficacité prédictive de ces paramètres, tout en maintenant les
 paramètres grammaticaux à des valeurs fixes.
 
 Le principal avantage de cette approche est que, pour chaque phrase source e, le modèle de langage
 conditionnel se réduit, en fait, à un simple modèle markovien caché p  (e)(f); le problème de la dictée
 de traduction adopte alors une forme familière en reconnaissance de la parole, soit :
 
                $f = argmaxf p (e)(f) p (s lf)
                                
 pour laquelle il existe de puissantes techniques de recherche (Bahl et al. [2]).
 
 
 6. Conclusions
 
 Une nouvelle génération d'aides à la traduction se profile déjà à l'horizon.  Grâce au développement des
 techniques d'analyse de traductions, les postes de travail de traducteurs pourront bientôt mettre à la
 disposition de leurs utilisateurs des outils qui dépasseront les simples fonctions de bureautique. Les
 traducteurs seront bientôt en mesure de tirer profit du vaste potentiel inexploité que recèle leur production
 antérieure.  Ils disposeront bientôt d'outils de vérification qui les aideront à détecter les erreurs de
 traduction présentes dans leurs premiers jets.  Et il y a de bonnes chances que la transcription
 automatique de la parole se concrétise en traduction bien avant qu'elle ne devienne une réalité pour les
 applications unilingues. 
 
 Nous ne serions pas surpris de voir cette liste d'applications basées sur le concept de l'analyse de
 traductions s'allonger rapidement.  Nous ne souhaitons que du bien à la TA classique, mais nous croyons
 que c'est dans le domaine des aides à la traduction que se produiront les véritables progrès, et ce,
  pendant de nombreuses années encore! 

 Références bibliographiques
 
[1]  Bar-Hillel, Y. : «The State of Machine Translation in 1951¯, in American Documentation, vol. 2,
      1951, p. 229-237.

[2]  Bahl, L., Jelinek, F. et R. Mercer : «A maximum likelihood approach to continuous speech
      recognition¯, IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-5(2), p.
      179-191, mars 1983.

[3]  Brown, P., Lai, J. et R. Mercer : «Aligning sentences in parallel corpora¯, Proceedings of the 29th
      Annual Meeting of the Association for Computational Linguistics, Berkeley (Californie), juin 1991.

[4]  Brown, P., Chen, S., Della Pietra, S., Della Pietra, V., Kehler, S. et R. Mercer : «Automatic
      speech recognition in machine aided translation¯, 1992 (à paraître).

[5]  Brown, P., Della Pietra, S., Della Pietra, V., et R. Mercer : «The Mathematics of Machine
      Translation: Parameter Estimation¯, (à paraître).

[6]  Church, K. et W. Gale : «Concordances for Parallel Texts¯, in Proceedings of the 7th Annual
      Conference of the UW Centre for NOED and Text Research, Oxford, 1991.

[7]  Debili, F. et E. Sammouda : «Appariement des phrases de textes bilingues français-anglais et
      français-arabes, in Proceedings of COLING-92, Nantes, 1992.

[8]  Dymetman, M. : Transformations de grammaires logiques et réversibilité en traduction
      automatique, thèse d'État, Université de Grenoble 1, France, 1992.

[9]  Dymetman, M., Foster, G. et P. Isabelle : Towards an Automatic Dictation System for Translators
      (TransTalk), rapport technique, CITI (CITI), Laval (Québec), Canada, 1992.

[10] Foster, G. : Statistical Lexical Disambiguation, mémoire de maîtrise, McGill University, School
      of Computer Science, 1991.

[11] Gurstein, M. et M. Monette : Functional Specifications for a Translator's Workstation, rapport
      technique 12SD.36902-5-0003, Socioscope Inc., Ottawa, Canada, octobre 1988.  Rapport
      présenté au Centre canadien de recherche sur l'informatisation du travail (Centre d'innovation
      en technologies de l'information).

[12] Isabelle, P. : «Machine Translation at the TAUM Group¯, in Margaret King (éd.), Machine
      Translation Today: The State of the Art, Edinburgh University Press, 1987.

[13] Isabelle, P. : «Bi-Textual Aids for Translators¯, in Proceedings of the Eighth Annual Conference
      of the UW Centre for the New OED and Text Research, University of Waterloo, Waterloo,
      Canada, 1992.

[14] Isabelle, P., Dymetman, M. et E. Macklovitch : «CRITTER: a Translation System for Agricultural
      Market Reports¯, in Proceedings of COLING-88, Budapest, 1988.

[15] Jelinek, F. : «Self-Organized Modeling for Speech Recognition¯, in Alex Waibel et Kai-Fu Lee,
      éditeurs, Readings in Speech Recognition, p. 450-506, Morgan Kaufman, San Mateo, Californie,
      1990.

[16] Macklovitch, E. : «Corpus-Based Tools for Translators¯, in Proceedings of the 33rd Annual
      Conference of the American Translators Association, San Diego, 1992.

[17] Macklovitch, E. : A Third Version of the CWARC's Workstation for Translators, rapport
      technique, CWARC (CITI), Laval (Québec), Canada, 1993.

[18] Kay, M. : The Proper Place of Men and Machines in Translation, CSL-80-11, Xerox PARC, 1980.

[19] Sato, S. et M. Nagao : «Toward Memory-Based Translation¯, in Proceedings of COLING-90, p.
      247-252, 1990.

[20] Simard, M., Foster, G. et P. Isabelle : «Using Cognates to Align Sentences in Parallel Corpora¯,
      in Proceedings of the 4th International Conference on Theoretical and Methodological Issues
      in Machine Translation, Montréal, 1992.

[21] Van Noord, G. : Reversibility in Natural Language Processing, CIP-Gegevens Konincklijke
      Bibliotheek, La Haye, 1993.

[22] Van Roey, J., Granger, S. et H. Swallow : Dictionnaire des faux-amis français-anglais, Paris,
      Duculot, 1988.
<!DOCTYPE CESANA PUBLIC "-//CES//DTD cesAna//EN" >
<CESANA VERSION="1.12">
<CHUNKLIST>
<CHUNK>
<PAR>
<S ID="150">
Figure 3: A tripartite model for translation analysis Figure 1: A translation analysis tree (TAT) Figure 2: Sentence alignment as a simple case of TAT
</S>
<S ID="200">
Translation Analysis  and Translation Automation
</S>
<S ID="216">
ABSTRACT
</S>
<S ID="352">
We argue that the concept of translation analysis provides a suitable foundation  for a new generation of translation support tools.
</S>
<S ID="559">
We show that pre-existing  translations can be analyzed into a structured translation memory and describe our TransSearch bilingual concordancing system, which allows translators to harness such a memory.
</S>
<S ID="783">
We claim that translation analyzers can help detect  translation errors in draft translations and we present the results of an experiment on the detection of deceptive cognates conducted as part of our TransCheck project.
</S>
<S ID="942">
Finally, we claim that translation analysis can facilitate the speech-to-text  transcription of dictated translations and introduce our new TransTalk project.
</S>
<S ID="946">
1.
</S>
<S ID="959">
Introduction
</S>
<S ID="1043">
In 1951, Y. Bar-Hillel, the first full-time researcher in MT, wrote the following:
</S>
<S ID="1227">
"For those targets in which high accuracy is a conditio sine qua non, pure MT has to be given up  in favor of mixed MT, i.e., a translation process in which a human brain intervenes.
</S>
<S ID="1255">
There the  question arises:
</S>
<S ID="1319">
Which parts of the process should be given to a human partner?"
</S>
<S ID="1345">
(Bar-Hillel [1],  p. 230)
</S>
<S ID="1461">
Forty-two years and three `generations' of systems later, pure MT is not more widely applicable  than it was then.
</S>
<S ID="1507">
More discouraging still, neither is mixed MT.
</S>
<S ID="1709">
While precise figures are not  readily available, it appears safe to assume that the current share of anything that could be called MT, pure or mixed, is well below 1% of the total translation market.
</S>
<S ID="1911">
One is forced to conclude that  the MT community has so far failed to come up with realistic and practical answers to Bar-Hillel's question about the optimal division of labor between man and machine.
</S>
<S ID="2116">
Bar-Hillel himself ventured to suggest a man-machine tandem in which the human partner would  intervene either before or after the mechanical process, "but preferably not somewhere in the midst of it."
</S>
<S ID="2198">
That is, the machine would take care of the core part of the translation process.
</S>
<S ID="2291" new>
Ever  since, `human-aided MT' has remained the predominant paradigm within the MT community.
</S>
<S ID="2387">
Machines have persistently been asked to do something they fail to do well: namely, translate.
</S>
<S ID="2623">
And  humans have persistently been asked to do things they would rather not do, like inserting strange codes into source texts, answering odd questions about phrase bracketings or rearranging bizarre jumbles of target language words.
</S>
<S ID="2745">
In any case, the market response to this kind of man/machine  modus vivendi has consistently been less than enthusiastic.
</S>
<S ID="2892">
It has become obvious that, generally speaking, machines still cannot successfully assume  control over the core part of the translation process.
</S>
<S ID="3076">
As far back as 1980, Martin Kay [18]  forcefully argued for a reversal of roles in which the machine is sent back to its `proper place', that of an assistant to the human translator:
</S>
<S ID="3250">
"I want to advocate a view of the problem in which machines are gradually, almost  imperceptibly, allowed to take over certain functions in the overall translation process.
</S>
<S ID="3327">
First they  will take over functions not essentially related to translation.
</S>
<S ID="3391">
Then, little by little, they will  approach translation itself.
</S>
<S ID="3420">
The keynote will be modesty.
</S>
<S ID="3485">
At each stage, we will do only what we  know we can do reliably.
</S>
<S ID="3516">
Little steps for little feet!"
</S>
<S ID="3524">
(p. 11)
</S>
<S ID="3723">
It is precisely this kind of down-to-earth approach that the Center for Information Technology  Innovation (CITI chose to pursue when it launched its translator's workstation project back in 1987.
</S>
<S ID="4040">
In its current incarnation, the CITI's workstation provides the translator with a windowing  environment where he/she has simultaneous access to a number of tools such as split screen word processing, spelling correction, terminology and dictionary lookup, file comparison, word counting, full-text retrieval, etc.
</S>
<S ID="4060">
(Macklovitch [17]).
</S>
<S ID="4173">
Admittedly, this has more to do with office  automation for translators than with translation automation per se.
</S>
<S ID="4323">
But following Kay's proposed  scenario, we can now take advantage of this computer base and progressively enrich it with translation-oriented tools.
</S>
<S ID="4394">
From this perspective, the central issue can be formulated as follows:
</S>
<S ID="4502">
beyond office automation, but short of machine translation, what else can be done to  support translators?
</S>
<S ID="4690">
In the remainder of this paper, we argue that the concept of translation analysis constitutes a  suitable foundation for the development of a new generation of translation support tools.
</S>
<S ID="4764">
Section 2  is a general discussion of the notion of translation analysis.
</S>
<S ID="4915">
Sections 3, 4 and 5 describe our work  on three applications: the translation memory, the translation checker and the translator's dictation machine.
</S>
<S ID="4919">
2.
</S>
<S ID="4940">
Translation Analysis
</S>
<S ID="5183">
In recent literature (e.g. Isabelle, Dymetman & Macklovitch [14]), translation is often  conceptualized as a relation trL1,L2(S, T) whose extension is a set of pairs <S,T> such that S is a text of language L1 and T is a text of language L2.
</S>
<S ID="5359">
Since the number of texts in each language is  infinite, trL1,L2 has to be be defined recursively, with the consequence that the relation will have a compositional character:
</S>
<S ID="5495" new>
down to the level of some finite set of primitive elements, S and T will be  decomposed respectively into sets of elements {s1, s2, ...
</S>
<S ID="5517" new>
, sn} and {t1, t2, ...
</S>
<S ID="5589">
, tn}, in such a way that  for any i, trL1,L2(si, ti) is also satisfied.
</S>
<S ID="5823">
An ordinary MT system embodies some (possibly partial) specification of a translation relation  trL1,L2, together with a procedure which, given any value of S, will return one or several values T such that <S,T> belongs to trL1,L2.
</S>
<S ID="5989">
A reversible MT system (see for example Dymetman [8], Van  Noord [21]) can in addition compute, for any value of T, the values S for which <S,T> belongs to trL1,L2.
</S>
<S ID="6144">
While MT systems deal with the problem of producing translations, we can also, as noted by Debili  [7], view translations from a recognition perspective.
</S>
<S ID="6282">
We will call a translation acceptor any  procedure which, given some particular pair <S,T>, can decide whether or not trL1,L2(S,T) holds.
</S>
<S ID="6465">
Furthermore, we will call a translation analyzer any recursive procedure ta(<S,T>, TAT) that  assigns to those pairs <S,T> that satisfy trL1,L2(S,T) a translation analysis tree TAT.
</S>
<S ID="6541">
A TAT makes  explicit the compositional makeup of the translation relation.
</S>
<S ID="6709">
For example, given some suitable  definition of the English-French translation relation, a translation analyzer could produce a TAT such as the one shown in Figure 1.
</S>
<S ID="6866">
Isabelle [13] uses the term bi-text to designate structures which, like TAT's, are meant to  decompose translations into their constituent correspondences.
</S>
<S ID="7012">
TAT's are structural descriptors for  translation analyses in the same way that parse trees are structural descriptors for grammatical analyses.
</S>
<S ID="7083">
In principle, translation analysis and MT are very similar problems:
</S>
<S ID="7148">
the computation is based on  the same abstract relation trL1,L2.
</S>
<S ID="7195">
The difference is only in the computing modes.
</S>
<S ID="7310">
Does this mean  that in practice translation analyzers and MT systems are subject to exactly the same limitations?
</S>
<S ID="7436">
In particular, does this mean that useful translation analyzers are feasible if and only if useful MT  systems are feasible?
</S>
<S ID="7451">
Clearly not.
</S>
<S ID="7605">
Of course, in those rare cases where high-quality MT is feasible, it should be possible  to build a translation analyzer for the output of the MT system.
</S>
<S ID="7824">
But more importantly, in cases  where MT is not possible, we claim that it is still possible to develop analyzers for the translations produced by human translators, and that there will be many uses for these devices.
</S>
<S ID="8015">
This difference  stems from the practical requirements that different tasks (MT versus translation analysis) impose on the level of precision in the formal characterization of trL1,L2(S,T).
</S>
<S ID="8122">
Consider for example the model that underlies the sentence alignment method proposed by  Brown & al. [3].
</S>
<S ID="8204">
Conceptually, this model generates sequences of pairs of <S,T> in such a way that
</S>
<S ID="8208">
a)
</S>
<S ID="8351">
S is a sequence <s1, s2, ... sn> in which each si is itself a sequence of 0, 1 or 2 `sentences' and  T is a similar sequence <t1, t2, ... tn>;
</S>
<S ID="8354">
b)
</S>
<S ID="8427">
a `sentence' is any string of tokens terminated by a  punctuation token;
</S>
<S ID="8430">
c)
</S>
<S ID="8506">
a token is any string of characters appearing between delimiter characters;
</S>
<S ID="8510">
d)
</S>
<S ID="8860">
the length l(si) of each si (in terms of the number of tokens it contains) is correlated with the  length l(ti) of the corresponding ti according to a probability distribution Pr(l(s)|l(t)); and e) this probability distribution can be estimated from frequencies observed in corpora of translations, like the Hansard corpus of English/French texts.
</S>
<S ID="9032">
This model does capture one specific aspect of the translation relation between two languages,  namely length correlations between sentences that are mutual translations.
</S>
<S ID="9113">
In this sense it  constitutes a translation model, albeit an extremely weak one.
</S>
<S ID="9430">
If we were to apply a model of this kind to the task of translating English texts into French, an  English sentence e would be translated more or less as random sequence of characters f, whose only notable property is to have a length l(f) that is typical for a translation of an English sentence of length l(e).
</S>
<S ID="9494">
Such an `MT system' would appear perfectly useless in practice.
</S>
<S ID="9763">
On the other hand, if like Brown & al. we apply their model to the task of translation analysis, we  get a system capable of analyzing pre-existing translations into representations in which their compositional makeup is made explicit down to the level of sentences.
</S>
<S ID="9912">
The result is a TAT of the  form shown in Figure 2, in which texts S and T are decomposed into n successive pairs of blocks si and ti of sentences.
</S>
<S ID="9953">
Admittedly, the analysis is very crude:
</S>
<S ID="10015">
no correspondences are established below the sentence  level.
</S>
<S ID="10153">
Still, as we will see shortly, these `low-resolution' bi-texts provide an adequate basis for  some very useful translation support tools.
</S>
<S ID="10236">
Of course, richer analyses would open up even more possibilities in this respect.
</S>
<S ID="10500">
And in fact, is not  too hard to imagine families of somewhat stronger translation models which, while still insufficient for successful MT, could be used to successfully uncover more structure in pre-existing translations (e.g. phrase or word correspondences).
</S>
<S ID="10624">
With respect to their general architecture, models used for translation analysis can be very close  to those used for MT.
</S>
<S ID="10711">
The most obvious possibility is perhaps the tripartite model illustrated in  Figure 3.
</S>
<S ID="10902">
Just as in the well-known transfer model of MT, there are two language-specific  components (the language models), and one pair-specific, `contrastive' component (the correspondence model).
</S>
<S ID="11177">
Both monolingual components operate in the analysis mode and the  language-specific representations that they produce are fed into the correspondence model, which connects them into a single bi-textual representation in which translation correspondences are made explicit.
</S>
<S ID="11315">
This model remains a natural one regardless of whether its components are  implemented by means of rule-based or corpus-based techniques.
</S>
<S ID="11432">
In fact, even the simple length- based alignment method mentioned above is best conceptualized as an instance of it.
</S>
<S ID="11594">
In the development of general-purpose translation analyzers, there is some evidence to suggest  that probabilistic models will turn out to be extremely useful.
</S>
<S ID="11875">
While rule-based methods work well  for the development of `deep' models in narrow domains, probabilistic methods appear especially well-suited to the development of shallow models potentially capable of providing reasonably good partial analyses of non-restricted translations.
</S>
<S ID="12066">
In any case, our basic claim here is only that translation analysis, even based on weak translation  models, provides the right foundation for a new generation of translation support tools.
</S>
<S ID="12121">
We now  turn to an examination of some of these tools.
</S>
<S ID="12125">
3.
</S>
<S ID="12144">
Translation Memory
</S>
<S ID="12149">
3.1
</S>
<S ID="12185">
Existing Translations as a Resource
</S>
<S ID="12381">
The trend towards corpus-based approaches in MT stems in part from a realization that the  existing body of translations is an immensely rich resource whose potential has so far been neglected.
</S>
<S ID="12517">
In fact, it is clear that existing translations contain more solutions to more  translation problems than any other available resource.
</S>
<S ID="12719">
But translators will only be able to tap the riches buried in their past production once they are  provided with tools capable of managing it as translation data rather than as word-processing data.
</S>
<S ID="12886">
This is precisely what a translation analyzer sets out to do: upgrade word-processing data  into bi-textual structures that make translation correspondences explicit.
</S>
<S ID="13031">
Once pre-existing translations are organized in that way, corresponding source and target  language segment are systematically linked together.
</S>
<S ID="13187">
In particular, any segment containing an  instance of some translation problem is linked with a segment containing a ready-made solution for that problem.
</S>
<S ID="13354">
If we provide translators with the means to create, store and search such bi- textual structures, their past production becomes a highly effective translation memory.
</S>
<S ID="13359">
3.2
</S>
<S ID="13369">
TransBase
</S>
<S ID="13559">
In order to render accessible the results of translation analyses of large quantities of text, we have  devised a simple model for a structured translation memory, which we call TransBase.
</S>
<S ID="13628">
It shares  the basic characteristics of full-text retrieval systems:
</S>
<S ID="13771">
it can manage arbitrary amounts of text, it  can be enlarged incrementally and it allows rapid access to the textual contents of the database.
</S>
<S ID="13873">
Its essential difference with these systems is its ability to also store bi-textual representations.
</S>
<S ID="13981">
A TransBase database is constructed using a translation analyzer similar to the one depicted in  Figure 2.
</S>
<S ID="14191">
Each document in a pair of mutual translations is submitted to a language-specific  analysis which breaks it down into its structural elements (paragraphs, sentences, etc.) and determines its lexical content.
</S>
<S ID="14346">
This information is stored in two distinct language-specific  components of the database, and indexed so as to allow rapid access to any part of the text.
</S>
<S ID="14577">
A  "correspondence analyzer" based on the techniques described in Simard, Foster & Isabelle [20] then uses these language-specific analyses to construct a sentence-level "translation map", which is also stored into the database.
</S>
<S ID="14661">
The structure and construction scheme of the database are  illustrated in Figure 4.
</S>
<S ID="14674">
Figure 4:
</S>
<S ID="14719">
General organization of a TransBase database
</S>
<S ID="14808">
The texts of the source and target languages are handled symmetrically in the database.
</S>
<S ID="14944">
However,  since the directionality of the translation may be important to the user, TransBase can record which language is the source.
</S>
<S ID="14949">
3.3
</S>
<S ID="14961">
TransSearch
</S>
<S ID="15029">
There are many possible ways to exploit such a translation memory.
</S>
<S ID="15212">
The first one that comes to  mind, and probably the most universally useful, is to provide translators with tools to search a TransBase database on the basis of its textual content.
</S>
<S ID="15381">
It has already been suggested that a tool  capable of producing bilingual concordances would be useful to bilingual lexicographers (see for example Church & Gale [6]).
</S>
<S ID="15469">
It is rather obvious that bilingual concordancing would also be useful  to translators.
</S>
<S ID="15688">
For example, upon encountering some occurrence of an expression like to be out to  lunch or to add insult to injury in his English source\x11text, a translator might be hesitant as to an appropriate French equivalent.
</S>
<S ID="15790">
He/she might also find that conventional bilingual dictionaries do  not provide satisfactory answers.
</S>
<S ID="15949">
Bilingual concordancing would enable him/her to retrieve  examples of these expressions together with their translations in a database of the TransBase kind.
</S>
<S ID="16099" new>
This could be useful not only for idiomatic expressions, but also for specialized terminology  or domain-specific formulae (To whom it may concern...
</S>
<S ID="16117">
, Attendu que...).
</S>
<S ID="16185">
See Macklovitch [16] for  a more detailed discussion of this issue.
</S>
<S ID="16220">
TransSearch is just such a tool:
</S>
<S ID="16357">
it allows one to extract occurrences of specific `expressions' from  the database, and to visualize them within their bilingual context.
</S>
<S ID="16551" new>
Because the software is primarily  aimed at translators, who are likely to use it as just another reference source, it is designed to be used interactively and to provide answers in real-time.
</S>
<S ID="16655">
This is just what the inclusion of word-form  indexes within the TransBase model is meant to allow for.
</S>
<S ID="16795">
Because most translators are not computer experts, much attention has been devoted to the user- friendliness of the TransSearch interface.
</S>
<S ID="16918">
Using an intuitive, graphically-oriented query language,  it is easy for a user to submit complex queries to the database.
</S>
<S ID="16993">
Every such query defines a logical  expression on sequences of word-forms:
</S>
<S ID="17132">
when the query is submitted, the system produces all the  couples that satisfy this expression in the alignment component of the database.
</S>
<S ID="17318">
In addition, the  inclusion of dictionaries and morphological descriptions of both French and English allows TransSearch to automatically match any inflectional variant of query items.
</S>
<S ID="17435">
The result of a query is normally presented in a two-column format, where mutual translations  appear side-by-side.
</S>
<S ID="17646">
The user can either examine one match at a time within the document from  which it was drawn, or collect all matches with a small portion of their immediate context, the way concordances are usually presented.
</S>
<S ID="17709">
Figure 5 gives an idea of a typical session with TransSearch.
</S>
<S ID="17984">
In this example, the user has queried  the system for occurrences of the English expression take X to court which are not translated in French as poursuivre X or intenter un (or des) procès à X, and the database searched consists of the 1986 Canadian Hansard translations.
</S>
<S ID="18114">
The translators to whom we have shown the system  invariably concluded that bilingual concordancing would be very useful to them.
</S>
<S ID="18127">
Figure 5:
</S>
<S ID="18154">
A session with TransSearch
</S>
<S ID="18158">
4.
</S>
<S ID="18179">
Translation checking
</S>
<S ID="18184">
4.1
</S>
<S ID="18225">
Translation Analysis and Error Detection
</S>
<S ID="18426">
In recent years, we have witnessed the appearance on the market of text critiquing tools meant to  help writers improve their texts by spotting potential problems in spelling, grammar and even style.
</S>
<S ID="18700">
While these tools can in principle help translators correct writing errors in the target language text,  there is no way they can help them correct translation errors in the strict sense of the term, that is, incorrect correspondences between the source and target texts.
</S>
<S ID="18864">
For example, they cannot help  with cases of mistranslation in which both texts are individually correct and meaningful, but do not happen to mean the same thing.
</S>
<S ID="18968">
Such errors can only be detected by a device that simultaneously  examines the source and target texts.
</S>
<S ID="19033">
In other words, a device that comprises a translation  analyzer.
</S>
<S ID="19361">
Given a translation analyzer capable of reconstructing some subset Cset of the correspondences  that are observable in the result of some translation operation, and given some set of constraints C on admissible correspondences, a translation checker is a device that helps the translator ensure that Cset indeed satisfies C.
</S>
<S ID="19550">
This requires a translation analyzer based on a `robust' translation  model, a model capable of observing actual correspondences that may be deviant with respect to the norm defined by C.
</S>
<S ID="19637">
The general problem of translation quality is a notoriously complex and vexing issue.
</S>
<S ID="19740">
It is certainly  not our intention to propose any global metric or method for evaluating translations.
</S>
<S ID="19765">
Our aim is  more modest.
</S>
<S ID="19957">
We only want to identify some particularly simple properties that most translators  will want their translations to possess and devise some tools that will help them verify these properties.
</S>
<S ID="20020">
One rather obvious candidate is the property of exhaustivity.
</S>
<S ID="20116">
Normally, all parts of the source text  should have a corresponding element in the target text.
</S>
<S ID="20251">
But translators sometimes make omission  errors, forgetting for example to translate a sentence, a paragraph, or even a complete page.
</S>
<S ID="20401">
In  such cases an adequate translation analyzer should realize that a source language segment is being mapped onto an empty target language segment.
</S>
<S ID="20512">
The checking device could then warn the  translator, pointing out a possible problem in his draft translation.
</S>
<S ID="20570">
Another candidate property is terminological coherence.
</S>
<S ID="20721">
In technical translations, one and the  same target language term should be used to translate all occurrences of any particular source language term.
</S>
<S ID="20933">
A process of translation analysis capable of bringing out term correspondences  between a draft translation and its source would presumably make it possible to help translators enforce terminological coherence.
</S>
<S ID="21041">
A third constraint that translations are expected to obey is the absence of source language  interference.
</S>
<S ID="21147" new>
Some cases of interference result in constructs that are ill-formed with respect to the  target language.
</S>
<S ID="21220">
Their detection is possible without any need to look at the source text.
</S>
<S ID="21384">
For  example, if the English word address is translated as addresse (with two d's) in French, an ordinary French spell checker should be able to flag the problem.
</S>
<S ID="21492">
But there are also cases in  which interference results not in ill-formedness but rather in mistranslation.
</S>
<S ID="21570">
Deceptive cognates,  for example, tend to generate this kind of interference.
</S>
<S ID="21689">
Word we of language Le and word wf of language Lf are cognates when their forms are similar due  to shared etymology.
</S>
<S ID="21782">
For example, the English word `government' and the French word  `gouvernement' are cognates.
</S>
<S ID="21877">
Most often, these words are not only cross-linguistic homonyms but  they are synonyms as well.
</S>
<S ID="21928">
However, in some cases the synonymy does not hold.
</S>
<S ID="22089">
For example,  the following pairs of English/French cognates have completely disjoint meanings: <actual, actuel>, <library, librairie>, <physician, physicien>.
</S>
<S ID="22221">
Such cognates are said to be `deceptive'  because of the misleading semantic expectation induced by their morphological similarity.
</S>
<S ID="22410">
The  sentence Max se rendit à la librairie is perfectly well-formed in French, but used as a translation for Max went to the library, it would constitute a blatant case of mistranslation.
</S>
<S ID="22652">
To the extent that a  translation analyzer is capable of observing in a draft translation an actual correspondence between cognates known to be deceptive, this correspondence can be flagged as a possible error for the translator to verify.
</S>
<S ID="22760">
There are probably several other types of translation errors that translation analysis could help  detect.
</S>
<S ID="22800">
Research in this area is just starting.
</S>
<S ID="22966">
In order to get a better idea of the practical potential of  this approach we conducted an experiment on the detection of deceptive cognates in actual translations.
</S>
<S ID="22971">
4.2
</S>
<S ID="23024">
An Experiment on the Detection of Deceptive Cognates
</S>
<S ID="23116">
Deceptive cognates (DC's) can be subclassified as to whether they are complete or partial.
</S>
<S ID="23290">
Complete DC's, like the examples given above, have the property that their meanings are  completely disjoint, and as a consequence can never be used as mutual translations.
</S>
<S ID="23431">
Partial DC's,  on the other hand, have partially overlapping meanings, and are mutually translatable in some subset of their possible uses.
</S>
<S ID="23565">
For example, the French verb examiner is sometimes equivalent (`')  and sometimes non-equivalent (`') to the English verb to examine:
</S>
<S ID="23598">
The doctor examined his patient
</S>
<S ID="23630">
Le médecin examina son patient
</S>
<S ID="23666">
The professor examined his students
</S>
<S ID="23704">
Le professeur examina ses étudiants.
</S>
<S ID="23958">
Concentrating for the moment on the easier problem of complete DC's, we conducted an  experiment aimed at: 1) assessing the amplitude of the problem in actual translations; and 2) evaluating the effectiveness of some straightforward detection methods.
</S>
<S ID="24061">
We assembled a simple translation analyzer, TA1, that instantiates the model of Figure 1 as  follows:
</S>
<S ID="24226">
language models for French and English are reduced to processes of `tokenization' and  morphological analysis (based on a dictionary and a set of inflection rules).
</S>
<S ID="24323">
The output of these  language models is a simple morphological representation of the input text:
</S>
<S ID="24442">
each token is  represented as the set of citation forms of the lexical entries of which it is potentially an instance.
</S>
<S ID="24557">
The correspondence model used in TA1 is simply the sentence alignment program of Simard,  Foster & Isabelle [20].
</S>
<S ID="24620" new>
Its output representation is a sequence <<e1,f1>, <e2,f2>, ...
</S>
<S ID="24888">
<en,fn>> where  each ei is a sequence of zero, one or two morphologically represented sentences of the English text, each fj is a sequence of zero, one or two morphologically represented sentences of the French text, and each <ei,fi> is a translation correspondence.
</S>
<S ID="25066">
We extracted from van Roey & al. [22] a list of 145 word pairs which were classified as DC's of the  `complete' variety: <accomodate, accomoder>, <actually, actuellement>, etc.
</S>
<S ID="25293">
We then  implemented a straightforward checker that would search the output of TA1 and for each word pair <we, wf> would return the set of sentence pairs <ei, fi> such that we ¿ ei (i.e. ei contains the word we) and wf ¿ fi.
</S>
<S ID="25422">
Obviously, this condition can be met by pairs of sentences in which we and wf  appear without being used as mutual translations.
</S>
<S ID="25505">
We then tested this rather simplistic device on one year of Hansard translations.
</S>
<S ID="25630">
Hand-checking  the results, we found out that many genuine cases of translation errors were retrieved, as in the following:
</S>
<S ID="25716">
The peace movement in Canada is composed of physicians, members of the church, [...]
</S>
<S ID="25820">
-> Le mouvement canadien pour la paix compte dans ses rangs des physiciens, des  ecclésiatiques, [...]
</S>
<S ID="25844">
(Hansard, 1987/09/29)
</S>
<S ID="25928" new>
There are parts of this bill which concern librarians and the artistic community.
</S>
<S ID="26014">
-> Quelque part dans ce projet de loi, il est question des libraires et des artistes.
</S>
<S ID="26038">
(Hansard, 1987/11/30)
</S>
<S ID="26095">
But as Table 1 shows, the results were also very noisy.
</S>
<S ID="26107">
Table 1:
</S>
<S ID="26147">
Results of DC retrieval in TA1's output
</S>
<S ID="26200">
The noise was generated by three different sources.
</S>
<S ID="26303">
First, there are cases where the `deceptivity'  of <we, wf> is relative to their part of speech (POS).
</S>
<S ID="26423">
For example the French noun local and the  English noun local are complete DC's but their homograph adjectives are not.
</S>
<S ID="26507">
Since POS  information was not taken into account, irrelevant cases were retrieved.
</S>
<S ID="26577">
Second, some of the  noise was engendered by untranslated quotations.
</S>
<S ID="26647">
For example, agenda (English) and agenda  (French) are complete DC's.
</S>
<S ID="26953">
Since the forms are perfectly identical, our checker was unable to  distinguish among the two, and would consequently retrieve cases where agenda appears on both sides simply as a consequence of the fact that one of the texts contains it in the form of an untranslated quotation from the other language.
</S>
<S ID="27134">
Third, there were cases where we and wf did  appear in sentences that were mutual translations, but in such a way that these words were not themselves used as mutual translations.
</S>
<S ID="27239">
Our correspondence model (that is, sentence alignment)  was simply too coarse to filter out these cases.
</S>
<S ID="27307">
The breakdown between these noise sources  was as shown in Table 2.
</S>
<S ID="27319">
Table 2:
</S>
<S ID="27373">
Noise categorization for DC retrieval in TA1's output
</S>
<S ID="27433">
Given these figures, POS tagging was obviously called for.
</S>
<S ID="27615">
The translation analyzer was therefore  replaced with a new one, TA2, that differed from TA1 only in that its two language models were augmented with the POS tagger of Foster [10].
</S>
<S ID="27730">
The search process was modified so as to take  into account POS information associated with our 145 pairs of DC's.
</S>
<S ID="27801">
This scheme produced much  better results, as shown in Tables 3 and 4.
</S>
<S ID="27813">
Table 3:
</S>
<S ID="27853">
Results of DC retrieval in TA2's output
</S>
<S ID="27865">
Table 4:
</S>
<S ID="27919">
Noise categorization for DC retrieval in TA2's output
</S>
<S ID="28035">
POS tagging dramatically reduced the noise, with no more than a marginal effect on the recall  (one case is lost).
</S>
<S ID="28217">
This spectacular effect is in a large measure attributable to the resolution of  problems associated with a small number of frequent words (like the case of local mentioned above).
</S>
<S ID="28366">
Part of the remaining noise is due to tagging errors, but the largest proportion is now  attributable to the coarseness of our correspondence model.
</S>
<S ID="28418">
Better models would no doubt improve DC detection.
</S>
<S ID="28552">
However, the performance level of the  computationally cheap method tested here may well prove sufficient for real-life applications.
</S>
<S ID="28556">
5.
</S>
<S ID="28579">
Translation Dictation:
</S>
<S ID="28589">
TransTalk
</S>
<S ID="28796">
A recurring theme of this paper has been that weak models of translation, if used realistically, can  provide useful tools for the human translator, without imposing artificial constraints on his activity.
</S>
<S ID="29029">
One invaluable addition to the translator's workstation would be an automatic dictation module:  many professional translators prefer to dictate their translations rather than doing the typing themselves (Gurstein & Monette [11]).
</S>
<S ID="29207">
At the present time, speech-recognition technology is severely limited when confronted with large- vocabularies, and is therefore inapplicable to the task of most translators.
</S>
<S ID="29326">
An intriguing possibility,  however, is that of teaming the speech-recognition module with a (weak) translation model.
</S>
<S ID="29711">
The  MT model would then be used to make probabilistic predictions of the possible target language verbalizations freely produced by the translator, so as to dynamically reduce the "effective probable vocabulary" considered by the speech-recognition module on each dictation unit (sentence or paragraph) to such an extent that complete recognition of these units can be attempted.
</S>
<S ID="29875">
For example, it is clear that the probabilistic composition of the vocabulary considered by a speech  recognizer attempting to decode the spoken French sentence:
</S>
<S ID="30121">
Ces impôts cachés doivent être  acquittés par les pauvres aussi bien que par les riches should be markedly different depending on whether its English source The poor as well as the rich have to pay these extra hidden taxes is available or not.
</S>
<S ID="30271">
A French translation of this English sentence is for instance much more likely to  contain the word impôts than is a French sentence taken at random.
</S>
<S ID="30394">
It seems reasonable to hope  that a weak translation model could make this composition available to the speech recognizer.
</S>
<S ID="30491">
This idea was independently advanced by Dymetman, Foster & Isabelle [9] and by Brown & al. [4].
</S>
<S ID="30765">
We have launched a joint project with the speech-recognition group at CRIM (Centre de  Recherche Informatique de Montréal), the TransTalk project, aimed at proving the feasibility of the approach, using English as the source language and French as the dictation language.
</S>
<S ID="30880">
Initially we  intend to restrict dictation to an isolated-word mode, then to progress to a connected-speech mode.
</S>
<S ID="31138">
The TransSearch and TransCheck projects discussed above involved the development of  translation analyzers comprising French and English language models and a French-English correspondence model (sentence alignment) that were trained on the Hansard corpus.
</S>
<S ID="31289">
The  Hansard domain is thus a natural choice for the TransTalk project, since existing modules will then provide fundamental resources for TransTalk.
</S>
<S ID="31501">
Actually, one can view TransTalk as incorporating a  translation analyzer much like those described above, except that it has the capability of dealing with target language that is a spoken rather than written.
</S>
<S ID="31761">
TransTalk is based on a probabilistic model p of translation dictation relating an English written  textual unit e, its French written translation f (to simplify matters, we assume here that textual units are sentences), and the acoustic counterpart s of f.
</S>
<S ID="31891">
Both e and s are known to the system, and  TransTalk's job is to provide an estimate  of the actual f intended by the translator:
</S>
<S ID="31924">
One is thus led to define  as:
</S>
<S ID="32091">
that is,  is the most probable French sentence according to the model p, given both the source  English sentence and the acoustic realisation of the French sentence.
</S>
<S ID="32148">
By Bayes's formula, this equation can be rewritten as:
</S>
<S ID="32306">
where the last equality is a consequence of the mild assumption that once f is known, further  knowledge of e cannot add anything to the determination of s.
</S>
<S ID="32426">
This equation is strongly reminiscent of the "fundamental formula" of statistical speech-recognition  (Bahl & al [2]):
</S>
<S ID="32536">
where the distributions p(s | f) and p(f) are known as the acoustic model and language model  respectively.
</S>
<S ID="32851">
In the situation considered here, the pure language model p(f) has been replaced by  a "conditional language model" p(f | e), where knowledge of e "sharpens" the statistical structure of the language model, in particular by making it "concentrate" its attention on a limited lexical subset of the whole language.
</S>
<S ID="33124">
A quantitative measure of this "sharpening" can be given in terms of  perplexity, an information-theoretic quantity which measures the average uncertainty a given language model entertains about the next word to appear in a natural text, having seen the preceding words:
</S>
<S ID="33195">
the less the perplexity, the more predictive the model (Jelinek [15]).
</S>
<S ID="33535">
Brown et al.  [4] report the results of an experiment with the Hansards, using one of their simpler translation models (from French to English, in their case), which show the per-word perplexity of their pure (English) language model to average 63.3, while the perplexity of their conditional language model drops to an average of 17.2.
</S>
<S ID="33873">
These results are highly encouraging for the dictation task, for they  mean that the acoustic module should be able to discriminate, given one English spoken word, in average between 17.2 equiprobable candidates proposed by the conditional language model, as opposed to 63.3 equiprobable candidates proposed by the pure language model.
</S>
<S ID="33936">
Several approaches are possible to the modelling of p(f | e).
</S>
<S ID="34095">
A first approach, proposed by the IBM  team, is to use Bayes' formula and to write, by analogy to the standard formulation of the speech- recognition problem:
</S>
<S ID="34233">
where (in their terminology) p(e|f) is the "translation model", which plays a role similar to the  acoustic model in speech recognition.
</S>
<S ID="34413">
One is thus led to a symmetrical formula for the whole  translation dictation model where p(f) is the language model, p(s|f) the acoustic model, and p(e|f) the translation model.
</S>
<S ID="34445">
This method has two advantages:
</S>
<S ID="34449">
(1)
</S>
<S ID="34732">
it relies on a unique language model  for French, and (2) the work at IBM on statistical MT seems to indicate that even rough approximations to p(e|f), when teamed with a good language model for French, result in acceptable approximations to the conditional language model p(f|e).
</S>
<S ID="35111">
It is as if there were a  "division of work" between p(f), responsible for the well-formedness of French sentences, and p(e|f), responsible for pairing between English and French sentences (hence the somewhat misleading terminology "translation model") without much regard for either the internal structure of French or the internal structure of English(see [9] for details).
</S>
<S ID="35187">
The method has, however, one  important shortcoming in terms of processing:
</S>
<S ID="35342">
it requires an extensive search among the  sentences f in order to maximize p(e|f) p(f) (not counting the p(s|f) factor, which only makes matters worse).
</S>
<S ID="35562">
This is known to present serious practical difficulties in terms of non-optimal  search results as well as in terms of processing time, this last factor being obviously of central importance in a dictation application.
</S>
<S ID="35781">
A second approach to the modelling of p(f | e) is to consider a priori a certain parametrized family   of language models for French, to describe a mapping , and then to define the conditional language model through:
</S>
<S ID="35963">
Although it presents the inconvenience of dispensing with a unique reference language model for  French, this approach can be efficiently implemented if the family is well-chosen.
</S>
<S ID="36063">
One  possibility that we are currently investigating is to adapt a language model proposed in [10].
</S>
<S ID="36160">
This  model is a kind of "tri-POS" hidden Markov model, depending on two families of parameters.
</S>
<S ID="36335">
The  first family  gives the probability of generating a word having part-of-speech POSk, given that words with parts-of-speech POSi and POSj have been previously generated.
</S>
<S ID="36437">
The second family   gives the probability that a given part-of-speech POSi is associated with word w.
</S>
<S ID="36694">
That is,  conceptually at least, the model first generates part-of-speech strings, using a context window of the two previously generated parts-of-speech, then "decorates" each part-of-speech with a given word form, depending only on this part-of-speech.
</S>
<S ID="36858">
The  parameters represent an  approximation to the "grammatical" structure of French, while the  parameters represent an approximation to its "lexical" structure.
</S>
<S ID="36985">
We propose to experiment with a scheme where these parameters vary dynamically depending on  the observed source sentence e.
</S>
<S ID="37298">
One interesting possibility is to keep the "grammatical  parameters" fixed at their global French language values (neglecting the influence of the grammatical make-up of the English sentence on its translation), while modifying the "lexical" parameters depending on the lexical make-up of the English sentence.
</S>
<S ID="37565">
The first family of  parameters can be estimated reliably on a sufficiently large French corpus, while the second family of parameters, depending on e, can be estimated if certain simplifying assumptions akin to the Translation Model 1 of Brown & al. [5] are made.
</S>
<S ID="37747">
Basically, each  is considered to be  the average of the contributions  made by each English word we in e to the probability of realising part-of-speech POSi as the French word wf.
</S>
<S ID="37884">
In order to estimate the  parameters , it is necessary to have a pre-aligned training corpus of English- French bitexts (see section 3).
</S>
<S ID="38131">
It is then possible to start with initial guesses for the   parameters, and use standard reestimation techniques (see [5]) on this training corpus to maximize the predictive power of these parameters, while holding grammatical parameters fixed.
</S>
<S ID="38381">
The main advantage of this approach is that, for each source sentence e, the conditional language  model in effect reduces to a simple Hidden Markov Model , and the translation dictation problem then takes the form familiar in speech-recognition:
</S>
<S ID="38452">
for which powerful search techniques are available (Bahl & al [2]).
</S>
<S ID="38456">
6.
</S>
<S ID="38468">
Conclusions
</S>
<S ID="38542">
A new generation of translation support tools is just around the corner.
</S>
<S ID="38725">
Thanks to the development  of translation analysis techniques, translator's workstations will soon be able to offer much more  to their users than mere office automation functions.
</S>
<S ID="38831">
Translators will soon be in a position to tap  the vast potential lying dormant in their past production.
</S>
<S ID="38920">
They will soon be able to receive  assistance in checking their translations for errors.
</S>
<S ID="39028">
And speech input stands a good chance of  becoming a reality for them long before it does for monolinguals.
</S>
<S ID="39150">
We would not be surprised to see the list of applications based on the concept of translation  analysis expand rapidly.
</S>
<S ID="39268">
We wish classical MT well, but the real action is likely to be with  translator's aids for quite a few years to come!
</S>
<S ID="39280">
REFERENCES
</S>
<S ID="39285">
[1]
</S>
<S ID="39397">
Bar-Hillel Y., The State of Machine Translation in 1951, in American Documentation, vol. 2,  1951, pp. 229-237.
</S>
<S ID="39402">
[2]
</S>
<S ID="39597">
Bahl L., Jelinek F., Mercer R. A maximum likelihood approach to continuous speech  recognition, IEEE Transactions on Pattern Analysis and Machine Intelligence,   PAMI- 5(2):179--191, March 1983.
</S>
<S ID="39602">
[3]
</S>
<S ID="39722">
Brown P., Lai J., Mercer R., Aligning Sentences in Parallel Corpora, Proceedings of the 29th  Meeting of the ACL, 1991.
</S>
<S ID="39727">
[4]
</S>
<S ID="39867" new>
Brown P., Chen S., Della Pietra S., Della Pietra V., Kehler S., Mercer R. Automatic speech  recognition in machine aided translation, 1992.
</S>
<S ID="39880">
(to appear).
</S>
<S ID="39885">
[5]
</S>
<S ID="40013">
Brown P., Della Pietra S, Della Pietra V, Mercer R. The Mathematics of Machine  Translation: Parameter Estimation, (to appear).
</S>
<S ID="40018">
[6]
</S>
<S ID="40176">
Church K., Gale W., Concordances for Parallel Texts, in Proceedings of the 7th Annual  Conference the UW Centre for the NOED and Text Research, Oxford, 1991.
</S>
<S ID="40181">
[7]
</S>
<S ID="40327">
Debili F., Sammouda E., Appariement des phrases de textes bilingues Français-Anglais et  Français-Arabes, Proceedings of COLING-92, Nantes, 1992.
</S>
<S ID="40332">
[8]
</S>
<S ID="40483">
Dymetman M., Transformations de grammaires logiques et réversibilité en traduction  automatique, thèse d'État, Université de Grenoble 1, France, 1992.
</S>
<S ID="40488">
[9]
</S>
<S ID="40599" new>
Dymetman M., Foster G., Isabelle P., Towards an Automatic Dictation System for  Translators (Transtalk), Tech.
</S>
<S ID="40642">
report, CITI, Laval, Quebec, Canada, 1992.
</S>
<S ID="40648">
[10]
</S>
<S ID="40695" new>
Foster G., Statistical Lexical Disambiguation.
</S>
<S ID="40766">
Master's thesis, McGill University, School of  Computer Science, 1991.
</S>
<S ID="40772">
[11]
</S>
<S ID="40857" new>
Gurstein M. and Monette M. Functional Specifications for a Translator's Workstation.
</S>
<S ID="40881" new>
Technical Report 12SD.
</S>
<S ID="40942" new>
36902-5-0003, Socioscope Inc, Ottawa,   Canada, October 1988.
</S>
<S ID="41016">
Report submitted to the Canadian Workplace Automation Research  Center.
</S>
<S ID="41022">
[12]
</S>
<S ID="41182">
Isabelle P., Machine Translation at the TAUM Group, in Margaret King (ed.), Machine  Translation Today: The State of the Art, Edinburgh University Press, 1987.
</S>
<S ID="41188">
[13]
</S>
<S ID="41379">
Isabelle P., Bi-Textual Aids for Translators, Proceedings of the Eight Annual Conference  of the UW Centre for the New OED and Text Research, University of Waterloo, Waterloo, Canada, 1992.
</S>
<S ID="41385">
[14]
</S>
<S ID="41533">
Isabelle P., Dymetman M., Macklovitch E., CRITTER: a Translation System for Agricultural  Market Reports, Proceedings of COLING-88, Budapest, 1988.
</S>
<S ID="41539">
[15]
</S>
<S ID="41687" new>
Jelinek F. Self-Organized Modeling for Speech Recognition, in Alex Waibel and Kai-Fu Lee,  editors, Readings in Speech Recognition, pages 450--506.
</S>
<S ID="41726">
Morgan Kaufmann, San Mateo,  CA, 1990.
</S>
<S ID="41732">
[16]
</S>
<S ID="41885">
Macklovitch E., Corpus-Based Tools for Translators, Proceedings of the 33rd Annual  Conference of the American Translators Association, San Diego, 1992.
</S>
<S ID="41891">
[17]
</S>
<S ID="41973" new>
Macklovitch E., A Third Version of the CWARC's Workstation for Translators, Tech.
</S>
<S ID="42017">
report, CITI, Laval, Quebec, Canada, 1993.
</S>
<S ID="42023">
[18]
</S>
<S ID="42114">
Kay M., The Proper Place of Men and Machines in Translation, CSL-80-11, Xerox PARC,  1980.
</S>
<S ID="42120">
[19]
</S>
<S ID="42214">
Sato S., Nagao M., Toward Memory-Based Translation, Proceedings of COLING-90, 247- 252, 1990.
</S>
<S ID="42220">
[20]
</S>
<S ID="42440">
Simard M., Foster G., Isabelle P. Using Cognates to Align Sentences in Parallel Corpora,  Proceedings of the 4th International Conference on Theoretical and Methodological Issues in Machine Translation, Montreal, 1992.
</S>
<S ID="42446">
[21]
</S>
<S ID="42563">
Van Noord G., Reversibility in Natural Language Processing, CIP-Gegevens Konincklijke  Bibliotheek, The Hague, 1993.
</S>
<S ID="42569">
[22]
</S>
<S ID="42674">
Van Roey J., Granger S., Swallow H., Dictionnaire des faux-amis français-anglais, Paris,  Duculot, 1988.
</S>
</PAR>
</CHUNK>
</CHUNKLIST>
</CESANA>

# 常见的神经网络层
## 1. 线性层
### 1.1 什么是线性层
什么是线性层？顾名思义，线性层即进行一个线性运算的层。假定输入数据是一个张量 $X_{I,J,K}$, 输出数据是一个张量 $Y_{I, L}$。这里的大写下表代表张量每个维度的尺寸。我们可以引入如下线性运算，来实现张量$X$ 到 $Y$ 的映射：$$X_{I,J,K} M_{J,K,L}+B_{I, L}=Y_{I, L}$$
在实践中，这里的第一个维度(尺寸为$I$)，一般是 最小训练集的尺寸（batch size），$J,K$ 所对应的两个维度将缩并（矩阵内积）。线性层是最简单的神经网络层之一。根据普适近似定理（Universal approximation theorem）[^uat]，当我们把多个被有界并单调递增的函数（一般是激活函数）包裹起来的线性层嵌套叠加起来的时候，只要层数足够多，其就能用来以任意精度拟合任意函数。
[^uat]: [维基百科：普适近似定理（Universal approximation theorem）](https://en.wikipedia.org/wiki/Universal_approximation_theorem)
### 1.2 手把手构建一个线性层
接下来我们来手把手构建一个线性层，代码和注释如下：
### 1.3 线性层运用和特点探讨
## 2. 递归层
### 1.1 什么是递归层
### 1.2 手把手构建一个递归层
### 1.3 递归层运用和特点探讨
## 3. 卷积层
### 1.1 什么是卷积层
### 1.2 手把手构建一个卷积层
### 1.3 卷积层运用和特点探讨
## 4. 采样层
### 1.1 什么是采样层
### 1.2 手把手构建一个采样层
### 1.3 采样层运用和特点探讨
## 5. 激活层
### 1.1 什么是激活层
### 1.2 手把手构建一个激活层
### 1.3 激活层运用和特点探讨
## 6. 归一层
### 1.1 什么是归一层
### 1.2 手把手构建一个归一层
### 1.3 归一层运用和特点探讨
## 7. 填充层
### 1.1 什么是填充层
### 1.2 手把手构建一个填充层
### 1.3 填充层运用和特点探讨
## 8. 丢弃层
### 1.1 什么是丢弃层
### 1.2 手把手构建一个丢弃层
### 1.3 丢弃层运用和特点探讨